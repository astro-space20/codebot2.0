{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
    "os.environ[\"PINECONE_API_KEY\"] = \"56afd280-a522-4e0b-ab8b-4b651ec955ff\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models have gained significant attention in recent years due to their potential to revolutionize natural language processing (NLP) and various applications. Here are some reasons why fast language models are important:\n",
      "\n",
      "1. **Real-time processing**: Fast language models can process and respond to user queries or inputs in real-time, enabling applications like chatbots, virtual assistants, and language translation services to respond quickly and accurately.\n",
      "2. **Improved user experience**: By providing immediate results, fast language models can enhance the user experience in various applications, such as customer support, language learning, and gaming.\n",
      "3. **Increased efficiency**: Fast language models can speed up tasks like text classification, sentiment analysis, and named entity recognition, making them more efficient and cost-effective.\n",
      "4. **Scalability**: Fast language models can handle large volumes of data and scale to meet the demands of large-scale applications, such as social media and search engines.\n",
      "5. **Advancements in AI**: Fast language models can enable significant advancements in artificial intelligence (AI) and machine learning (ML) research, such as improved language understanding, dialogue generation, and text summarization.\n",
      "6. **Enhanced decision-making**: By providing accurate and timely insights, fast language models can support decision-making processes in various fields, such as finance, healthcare, and marketing.\n",
      "7. **Language understanding**: Fast language models can help improve language understanding by being able to process and analyze vast amounts of text data, enabling better entity recognition, sentiment analysis, and topic modeling.\n",
      "8. **Transfer learning**: Fast language models can be fine-tuned for specific tasks and domains, making them a versatile tool for NLP applications.\n",
      "9. **Improved dialogue systems**: Fast language models can enable more advanced and natural-sounding dialogue systems, such as conversational AI and voice assistants.\n",
      "10. **Potential applications**: Fast language models have the potential to be applied in various areas, such as:\n",
      "\n",
      "    * Virtual reality and gaming\n",
      "    * Autonomous vehicles\n",
      "    * Healthcare and medical research\n",
      "    * Customer service and support\n",
      "    * E-commerce and marketing\n",
      "\n",
      "In summary, fast language models have significant implications for various industries and applications, enabling faster, more efficient, and more accurate processing of natural language data.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from groq import Groq\n",
    "\n",
    "client = Groq(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=(\"GROQ_API_KEY\"),\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"you are a helpful assistant.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3-8b-8192\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarvesh/.conda/envs/rag/lib/python3.12/site-packages/pinecone/data/index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pc = Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"quickstart\"\n",
    "\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=1024, # Replace with your model dimensions\n",
    "    metric=\"cosine\", # Replace with your model metric\n",
    "    spec=ServerlessSpec(\n",
    "        cloud=\"aws\",\n",
    "        region=\"us-east-1\"\n",
    "    ) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'values': [0.04925537109375, -0.01313018798828125, ..., -0.01971435546875, -0.01107025146484375]}\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    {\"id\": \"vec1\", \"text\": \"Apple is a popular fruit known for its sweetness and crisp texture.\"},\n",
    "    {\"id\": \"vec2\", \"text\": \"The tech company Apple is known for its innovative products like the iPhone.\"},\n",
    "    {\"id\": \"vec3\", \"text\": \"Many people enjoy eating apples as a healthy snack.\"},\n",
    "    {\"id\": \"vec4\", \"text\": \"Apple Inc. has revolutionized the tech industry with its sleek designs and user-friendly interfaces.\"},\n",
    "    {\"id\": \"vec5\", \"text\": \"An apple a day keeps the doctor away, as the saying goes.\"},\n",
    "    {\"id\": \"vec6\", \"text\": \"Apple Computer Company was founded on April 1, 1976, by Steve Jobs, Steve Wozniak, and Ronald Wayne as a partnership.\"}\n",
    "]\n",
    "\n",
    "embeddings = pc.inference.embed(\n",
    "    model=\"multilingual-e5-large\",\n",
    "    inputs=[d['text'] for d in data],\n",
    "    parameters={\"input_type\": \"passage\", \"truncate\": \"END\"}\n",
    ")\n",
    "print(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 6}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wait for the index to be ready\n",
    "while not pc.describe_index(index_name).status['ready']:\n",
    "    time.sleep(1)\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "vectors = []\n",
    "for d, e in zip(data, embeddings):\n",
    "    vectors.append({\n",
    "        \"id\": d['id'],\n",
    "        \"values\": e['values'],\n",
    "        \"metadata\": {'text': d['text']}\n",
    "    })\n",
    "\n",
    "index.upsert(\n",
    "    vectors=vectors,\n",
    "    namespace=\"ns1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension': 1024,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'ns1': {'vector_count': 6}},\n",
      " 'total_vector_count': 6}\n"
     ]
    }
   ],
   "source": [
    "print(index.describe_index_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"give me the detailed code with steps for creating a new index in pinecone\"\n",
    "\n",
    "embedding = pc.inference.embed(\n",
    "    model=\"multilingual-e5-large\",\n",
    "    inputs=[query],\n",
    "    parameters={\n",
    "        \"input_type\": \"query\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'matches': [{'id': 'vec4',\n",
      "              'metadata': {'text': 'Apple Inc. has revolutionized the tech '\n",
      "                                   'industry with its sleek designs and '\n",
      "                                   'user-friendly interfaces.'},\n",
      "              'score': 0.724898577,\n",
      "              'values': []},\n",
      "             {'id': 'vec6',\n",
      "              'metadata': {'text': 'Apple Computer Company was founded on '\n",
      "                                   'April 1, 1976, by Steve Jobs, Steve '\n",
      "                                   'Wozniak, and Ronald Wayne as a '\n",
      "                                   'partnership.'},\n",
      "              'score': 0.714020133,\n",
      "              'values': []},\n",
      "             {'id': 'vec1',\n",
      "              'metadata': {'text': 'Apple is a popular fruit known for its '\n",
      "                                   'sweetness and crisp texture.'},\n",
      "              'score': 0.705669165,\n",
      "              'values': []}],\n",
      " 'namespace': 'ns1',\n",
      " 'usage': {'read_units': 6}}\n"
     ]
    }
   ],
   "source": [
    "results = index.query(\n",
    "    namespace=\"ns1\",\n",
    "    vector=embedding[0].values,\n",
    "    top_k=3,\n",
    "    include_values=False,\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tech company Apple is known for its innovative products like the iPhone.\n",
      "Apple Inc. has revolutionized the tech industry with its sleek designs and user-friendly interfaces.\n",
      "Apple Computer Company was founded on April 1, 1976, by Steve Jobs, Steve Wozniak, and Ronald Wayne as a partnership.\n"
     ]
    }
   ],
   "source": [
    "for result in results['matches']:\n",
    "    print(result['metadata']['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-16 11:14:03.360 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-16 11:14:03.362 WARNING streamlit.runtime.state.session_state_proxy: Session state does not function when running a script without `streamlit run`\n",
      "2024-10-16 11:14:03.363 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-16 11:14:03.364 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-16 11:14:03.365 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-16 11:14:03.448 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /home/sarvesh/.conda/envs/rag/lib/python3.12/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2024-10-16 11:14:03.450 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-16 11:14:03.451 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-16 11:14:03.451 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-16 11:14:03.452 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-16 11:14:03.453 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-16 11:14:03.454 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-16 11:14:03.455 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-16 11:14:03.456 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-16 11:14:03.456 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import streamlit as st\n",
    "import base64\n",
    "from groq import Groq\n",
    "\n",
    "client = Groq(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")\n",
    "\n",
    "st.session_state.api_key = os.environ.get(\"GROQ_API_KEY\")\n",
    "\n",
    "# Only show the API key input if the key is not already set\n",
    "if not st.session_state.api_key:\n",
    "    # Ask the user's API key if it doesn't exist\n",
    "    api_key = st.text_input(\"Enter API Key\", type=\"password\")\n",
    "    \n",
    "    # Store the API key in the session state once provided\n",
    "    if api_key:\n",
    "        st.session_state.api_key = api_key\n",
    "        st.rerun()  # Refresh the app once the key is entered to remove the input field\n",
    "else:\n",
    "    # If the API key exists, show the chat app\n",
    "    st.title(\"Chat App\")\n",
    "\n",
    "    # Initialize the chat message list in session state if it doesn't exist\n",
    "    if \"chat_messages\" not in st.session_state:\n",
    "        st.session_state.chat_messages = []\n",
    "\n",
    "    # Display previous chat messages\n",
    "    for messages in st.session_state.chat_messages:\n",
    "        if messages[\"role\"] in [\"user\", \"assistant\"]:\n",
    "            with st.chat_message(messages[\"role\"]):\n",
    "                st.markdown(messages[\"content\"])\n",
    "    \n",
    "    # Define a function to simulate chat interaction (you would replace this with an actual API call)\n",
    "    def get_chat():\n",
    "        embedding = pc.inference.embed(\n",
    "            model=\"multilingual-e5-large\",\n",
    "            inputs=[st.session_state.chat_messages[-1][\"content\"]],\n",
    "            parameters={\n",
    "                \"input_type\": \"query\"\n",
    "            }\n",
    "        )\n",
    "        results = index.query(\n",
    "            namespace=\"ns1\",\n",
    "            vector=embedding[0].values,\n",
    "            top_k=3,\n",
    "            include_values=False,\n",
    "            include_metadata=True\n",
    "        )\n",
    "        context = \"\"\n",
    "        for result in results['matches']:\n",
    "            context += result['metadata']['text'] + \"\\n\"\n",
    "            \n",
    "        chat_completion = client.chat.completions.create(\n",
    "            messages=st.session_state.chat_messages,\n",
    "            model=\"llama3-8b-8192\",\n",
    "        )\n",
    "        return chat_completion.choices[0].message.content\n",
    "\n",
    "    # Handle user input\n",
    "    if prompt := st.chat_input(\"Try asking the bot what it can do, or thank it for its help!\"):\n",
    "        # Display user message\n",
    "        with st.chat_message(\"user\"):\n",
    "            st.markdown(prompt)\n",
    "        st.session_state.chat_messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        # Get the assistant's response (in this case, it's just echoing the prompt)\n",
    "        with st.spinner(\"Getting responses...\"):\n",
    "            response = get_chat()\n",
    "        with st.chat_message(\"assistant\"):\n",
    "            st.markdown(response)\n",
    "        \n",
    "        # Add user message and assistant response to chat history\n",
    "        st.session_state.chat_messages.append({\"role\": \"assistant\", \"content\": response})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
